import time
from pymongo import MongoClient
from pymongo.operations import UpdateOne
from cluster import BERTopicModel
import chromadb
import numpy as np # Import numpy for potential use with embeddings if not already imported

class TwitterClustering:
    def __init__(self):
        """
        Initialize the TwitterClustering class.
        Connect to MongoDB and set up the required collections.
        """
        self.client = MongoClient('localhost', 27017)
        self.db = self.client["twitter_data"]
        self.tweet_filtered = self.db["tweet_filtered"]
        self.topic_status_change = self.db['topic_status_change']
        
        # Initialize ChromaDB client
        try:
            self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
            print("ChromaDB: Initialized persistent client at ./chroma_db")
        except Exception as e:
            print(f"ChromaDB: Failed to initialize persistent client: {e}. Falling back to in-memory.")
            self.chroma_client = chromadb.Client() # In-memory fallback
        self.chroma_collection = self.chroma_client.get_or_create_collection(name="tweet_rag_embeddings")
        print(f"ChromaDB: Collection 'tweet_rag_embeddings' loaded/created. Total items: {self.chroma_collection.count()}")


    def get_unclustered_tweets(self):
        """
        Retrieve unclustered tweets from the database.

        Returns:
        - tweet_txt_id: A list of dictionaries containing tweet IDs and texts.
        """
        filter = {'topic_label': {'$exists': False}}
        projection = {'_id': 1, 'text': 1}
        tweet_txt_id = list(self.tweet_filtered.find(filter, projection))
        return tweet_txt_id

    def update_tweet_clustering(self):
        """
        Update tweet clustering based on topic modeling.

        Returns:
        - topic_info: Information about the topics generated by the clustering.
        """
        tweets_to_cluster = self.get_unclustered_tweets()

        if not tweets_to_cluster:
            print("No tweets to cluster.")
            return None
        
        # tweets_to_cluster is a list of dicts, e.g. [{'_id': ObjectId('...'), 'text': '...'}, ...]
        # It's what BERTopicModel expects for its `tweet_dict` argument.
        
        clusterModel = BERTopicModel('cluster_model')
        # `online_topic_modeling` now returns (processed_tweets_data, topic_info)
        # `processed_tweets_data` is [{ "tweet_id": ..., "text": ..., "topic_label": ..., "embedding": ...}, ...]
        # `tweets_to_cluster` (which becomes `tweet_id_label` in old code) is passed to BERTopic and modified in place for topic labels.
        # The original `tweets_to_cluster` list of dicts will have 'topic_label' added/updated by BERTopicModel.
        
        processed_tweets_data, topic_info = clusterModel.online_topic_modeling(tweets_to_cluster)
        clusterModel.save_model()

        # MongoDB update operations using the original tweets_to_cluster list,
        # which should have been updated with topic_label by BERTopicModel.
        operations = []
        if tweets_to_cluster: # Ensure it's not empty
            operations = [
                UpdateOne({'_id': d['_id']}, {'$set': {'topic_label': d.get('topic_label', -2)}}) # Use .get for safety
                for d in tweets_to_cluster # This is the original list of dicts passed to BERTopic
            ]
            if operations: # only bulk_write if there are operations
                result = self.tweet_filtered.bulk_write(operations)
                print(f"MongoDB: Number of tweets updated with topic_label: {result.modified_count}")
            else:
                print("MongoDB: No topic label update operations to perform.")
        else:
            print("MongoDB: tweets_to_cluster list was empty, skipping topic_label updates.")

        # Store embeddings in ChromaDB
        if processed_tweets_data:
            print(f"ChromaDB: Preparing to add {len(processed_tweets_data)} embeddings.")
            try:
                ids_to_add = []
                embeddings_to_add = []
                metadatas_to_add = []
                
                for tweet_data in processed_tweets_data:
                    tweet_id_str = str(tweet_data['tweet_id'])
                    # Ensure embedding is a list of floats
                    embedding_list = np.array(tweet_data['embedding']).astype(float).tolist()

                    ids_to_add.append(tweet_id_str)
                    embeddings_to_add.append(embedding_list)
                    metadatas_to_add.append({
                        "tweet_id": tweet_id_str,
                        "topic_label": str(tweet_data['topic_label']),
                        "text": tweet_data['text']
                    })

                if ids_to_add:
                    self.chroma_collection.add(
                        ids=ids_to_add,
                        embeddings=embeddings_to_add,
                        metadatas=metadatas_to_add
                    )
                    print(f"ChromaDB: Successfully added {len(ids_to_add)} embeddings. Collection count: {self.chroma_collection.count()}")
                else:
                    print("ChromaDB: No valid data to add.")

            except Exception as e:
                print(f"ChromaDB: Error adding embeddings: {e}")
        else:
            print("ChromaDB: No processed tweet data with embeddings to add.")
            
        return topic_info

    def topics_to_delete(self, new_topic_dict):
        """
        Determine the topic labels to delete based on the new topics generated.

        Args:
        - new_topic_dict: A list of dictionaries representing the new topics.

        Returns:
        - labels_to_delete: A list of topic labels to delete.
        """
        new_topic_labels = set(topic['topic_label'] for topic in new_topic_dict)
        change_topic_labels = set(doc['topic_label'] for doc in self.topic_status_change.find())
        return list(change_topic_labels - new_topic_labels)

    def delete_tweets_by_cluster_label(self, labels_to_delete):
        """
        Delete tweets with specified cluster labels.

        Args:
        - labels_to_delete: A list of cluster labels to delete.
        """
        self.topic_status_change.delete_many({'topic_label': {'$in': labels_to_delete}})
        result = self.tweet_filtered.delete_many({'topic_label': {'$in': labels_to_delete}})
        print('Number of tweets deleted: ', result.deleted_count, 'Labels deleted: ', labels_to_delete)
    
    def delete_irrelevant_tweets(self):
        """
        For every cluster, delete all the tweets that are no longer relevant to the cluster
        by comparing cluster keywords to tweet text.
        """
        # TODO: Implement this function.
        
        pass

    def topics_over_time(self, new_topic_stats):
        """
        Track the changes in topics over time and update the topic status collection.

        Args:
        - new_topic_stats: Statistics and information about the new topics.
        """
        new_topics = new_topic_stats['topics']
        for new_topic in new_topics:
            doc = self.topic_status_change.find_one({'topic_label': new_topic['topic_label']})
            if doc:
                if doc['size'][len(doc['size'])-1] != new_topic['size'] or doc['keywords'][len(doc['keywords'])-1] != new_topic['keywords']:
                    doc['size'].append(new_topic['size'])
                    doc['keywords'].append(new_topic['keywords'])
                    doc['time'].append(new_topic_stats['time'])
                    self.topic_status_change.replace_one({'topic_label': new_topic['topic_label']}, doc)
            else:
                new_doc = {
                    'topic_label': new_topic['topic_label'],
                    'size': [new_topic['size']],
                    'keywords': [new_topic['keywords']],
                    'time': [new_topic_stats['time']]
                }
                self.topic_status_change.insert_one(new_doc)

if __name__ == '__main__':
    twitter_clustering = TwitterClustering()
    while True:
        new_topic_stats = twitter_clustering.update_tweet_clustering()
        if new_topic_stats:
          twitter_clustering.topics_over_time(new_topic_stats)
          labels_to_delete = twitter_clustering.topics_to_delete(new_topic_stats['topics'])
          twitter_clustering.delete_tweets_by_cluster_label(labels_to_delete)
          
        print('Sleeping for 5 minutes')
        time.sleep(300)
